{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a240fb",
   "metadata": {},
   "source": [
    "### Finetuning Longformer Binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea7c98f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:44:18.909767Z",
     "iopub.status.busy": "2024-03-28T08:44:18.908997Z",
     "iopub.status.idle": "2024-03-28T08:44:18.916441Z",
     "shell.execute_reply": "2024-03-28T08:44:18.915595Z",
     "shell.execute_reply.started": "2024-03-28T08:44:18.909732Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import logging\n",
    "from transformers import LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainingArguments, LongformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643cacc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T17:28:22.962766Z",
     "iopub.status.busy": "2024-03-26T17:28:22.962063Z",
     "iopub.status.idle": "2024-03-26T17:28:23.520783Z",
     "shell.execute_reply": "2024-03-26T17:28:23.520079Z",
     "shell.execute_reply.started": "2024-03-26T17:28:22.962732Z"
    }
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4aeef4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T17:28:23.522486Z",
     "iopub.status.busy": "2024-03-26T17:28:23.522145Z",
     "iopub.status.idle": "2024-03-26T17:29:30.089987Z",
     "shell.execute_reply": "2024-03-26T17:29:30.089068Z",
     "shell.execute_reply.started": "2024-03-26T17:28:23.522454Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraffalo8888\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240326_172857-oqsfxf8s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/raffalo8888/binaryclass_long/runs/oqsfxf8s' target=\"_blank\">vocal-bush-7</a></strong> to <a href='https://wandb.ai/raffalo8888/binaryclass_long' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/raffalo8888/binaryclass_long' target=\"_blank\">https://wandb.ai/raffalo8888/binaryclass_long</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/raffalo8888/binaryclass_long/runs/oqsfxf8s' target=\"_blank\">https://wandb.ai/raffalo8888/binaryclass_long/runs/oqsfxf8s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/raffalo8888/binaryclass_long/runs/oqsfxf8s?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x78fc91092440>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "wandb.init(project=\"binaryclass_long\", entity=\"raffalo8888\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfcde7de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T17:29:47.497123Z",
     "iopub.status.busy": "2024-03-26T17:29:47.496189Z",
     "iopub.status.idle": "2024-03-26T17:29:47.505412Z",
     "shell.execute_reply": "2024-03-26T17:29:47.504358Z",
     "shell.execute_reply.started": "2024-03-26T17:29:47.497083Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8332a52a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T00:21:14.696919Z",
     "iopub.status.busy": "2024-03-26T00:21:14.696004Z",
     "iopub.status.idle": "2024-03-26T00:21:15.501493Z",
     "shell.execute_reply": "2024-03-26T00:21:15.500512Z",
     "shell.execute_reply.started": "2024-03-26T00:21:14.696895Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/mergereddata/generated_pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c5933a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T00:21:15.503638Z",
     "iopub.status.busy": "2024-03-26T00:21:15.502697Z",
     "iopub.status.idle": "2024-03-26T00:21:15.511627Z",
     "shell.execute_reply": "2024-03-26T00:21:15.510808Z",
     "shell.execute_reply.started": "2024-03-26T00:21:15.503610Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Same_Category\"] = df[\"Same_Category\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd828e",
   "metadata": {},
   "source": [
    "### Fine Tuning modello "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5aafd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T17:29:53.837212Z",
     "iopub.status.busy": "2024-03-26T17:29:53.836835Z",
     "iopub.status.idle": "2024-03-26T17:29:53.850096Z",
     "shell.execute_reply": "2024-03-26T17:29:53.848996Z",
     "shell.execute_reply.started": "2024-03-26T17:29:53.837184Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "from torch import nn\n",
    "from transformers.models.longformer.modeling_longformer import LongformerPreTrainedModel, LongformerClassificationHead\n",
    "from transformers import LongformerModel\n",
    "\n",
    "class ModifiedModelForBinaryClassification(LongformerPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(ModifiedModelForBinaryClassification, self).__init__(config)\n",
    "        self.longformer = LongformerModel(config)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input_ids_1, attention_mask_1, input_ids_2, attention_mask_2, labels=None):\n",
    "       # global attention mask con attenzione solo sul primo token \n",
    "        global_attention_mask_1 = torch.zeros_like(input_ids_1)\n",
    "        global_attention_mask_1[:, 0] = 1 \n",
    "\n",
    "        global_attention_mask_2 = torch.zeros_like(input_ids_2)\n",
    "        global_attention_mask_2[:, 0] = 1  \n",
    "\n",
    "        outputs_1 = self.longformer(input_ids_1, attention_mask=attention_mask_1, \n",
    "                                    global_attention_mask=global_attention_mask_1)\n",
    "        sequence_output_1 = outputs_1['last_hidden_state']\n",
    "        cls_token_1 = sequence_output_1[:, 0, :]  \n",
    "\n",
    "        outputs_2 = self.longformer(input_ids_2, attention_mask=attention_mask_2, \n",
    "                                    global_attention_mask=global_attention_mask_2)\n",
    "        sequence_output_2 = outputs_2['last_hidden_state']\n",
    "        cls_token_2 = sequence_output_2[:, 0, :]  \n",
    "        #distanza del coseno tra cls1 e cls2\n",
    "        logits = cosine_similarity(cls_token_1, cls_token_2).unsqueeze(-1)  # Assicurati che i logits siano della forma [batch_size, 1]\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "                loss_fct = nn.BCEWithLogitsLoss()\n",
    "                labels = labels.view(-1, 1).float()  # Ridimensiona le etichette per batch_size =1\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, logits) if loss is not None else logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a84a10",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97709e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T17:31:53.970310Z",
     "iopub.status.busy": "2024-03-26T17:31:53.969448Z",
     "iopub.status.idle": "2024-03-26T17:31:53.980842Z",
     "shell.execute_reply": "2024-03-26T17:31:53.980005Z",
     "shell.execute_reply.started": "2024-03-26T17:31:53.970280Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextPairDataset(Dataset):\n",
    "    def __init__(self, text_pairs, labels, tokenizer, max_length=1024):\n",
    "        self.text_pairs = text_pairs\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        text1, text2 = self.text_pairs[idx]\n",
    "        tokenized_input1 = self.tokenizer(text1, return_tensors=\"pt\", max_length=self.max_length, truncation=True, padding='max_length')\n",
    "        tokenized_input2 = self.tokenizer(text2, return_tensors=\"pt\", max_length=self.max_length, truncation=True, padding='max_length')\n",
    "\n",
    "        return {\n",
    "        'input_ids_1': tokenized_input1['input_ids'].squeeze(0),\n",
    "        'attention_mask_1': tokenized_input1['attention_mask'].squeeze(0),\n",
    "        'input_ids_2': tokenized_input2['input_ids'].squeeze(0),\n",
    "        'attention_mask_2': tokenized_input2['attention_mask'].squeeze(0),\n",
    "        'labels': torch.tensor(self.labels[idx], dtype=torch.float)  \n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_pairs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cade5c4",
   "metadata": {},
   "source": [
    "### split dataset, instanziazione tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(15000) \n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df[['Text1','Text2']], df['Same_Category'], test_size=0.2)\n",
    "train_texts.to_csv(\"train_text.csv\")\n",
    "test_texts.to_csv(\"test_text.csv\")\n",
    "train_labels.to_csv(\"train_labels.csv\")\n",
    "test_labels.to_csv(\"test_labels.csv\")\n",
    "\n",
    "tokenizer = LongformerTokenizerFast.from_pretrained('allenai/longformer-base-4096',\n",
    "                                                    padding = 'max_length',\n",
    "                                                    truncation=True,max_length = 1024,\n",
    "                                                   )\n",
    "\n",
    "def tokenize_function(text1, text2):\n",
    "    return tokenizer(text1, text2, padding='max_length', truncation=True, max_length=1024)\n",
    "\n",
    "train_texts = [(row['Text1'], row['Text2']) for index, row in df.iterrows()]\n",
    "train_labels = df['Same_Category'].values\n",
    "\n",
    "test_texts = [(row['Text1'], row['Text2']) for index, row in df.iterrows()]\n",
    "test_labels = df['Same_Category'].values\n",
    "\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.float)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.float)\n",
    "\n",
    "train_dataset = TextPairDataset(train_texts, train_labels_tensor,tokenizer)\n",
    "test_dataset = TextPairDataset(test_texts, test_labels_tensor,tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb3dde9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:43:54.116803Z",
     "iopub.status.busy": "2024-03-26T15:43:54.116149Z",
     "iopub.status.idle": "2024-03-26T15:43:57.238345Z",
     "shell.execute_reply": "2024-03-26T15:43:57.237187Z",
     "shell.execute_reply.started": "2024-03-26T15:43:54.116770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a96124428e473aa3f7e3da7d7bdbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/597M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedModelForBinaryClassification.from_pretrained('allenai/longformer-base-4096', \n",
    "                                                            gradient_checkpointing=False,\n",
    "                                                             attention_window = 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c394be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T09:25:45.188535Z",
     "iopub.status.busy": "2024-03-27T09:25:45.187591Z",
     "iopub.status.idle": "2024-03-27T09:25:45.215420Z",
     "shell.execute_reply": "2024-03-27T09:25:45.214510Z",
     "shell.execute_reply.started": "2024-03-27T09:25:45.188500Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32a05d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T00:21:58.460590Z",
     "iopub.status.busy": "2024-03-26T00:21:58.460212Z",
     "iopub.status.idle": "2024-03-26T00:21:58.810806Z",
     "shell.execute_reply": "2024-03-26T00:21:58.809604Z",
     "shell.execute_reply.started": "2024-03-26T00:21:58.460558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModifiedModelForBinaryClassification(\n",
       "  (longformer): LongformerModel(\n",
       "    (embeddings): LongformerEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): LongformerPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d479b70",
   "metadata": {},
   "source": [
    "### Funzioni per calcolare le metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80bdaf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T17:30:07.286077Z",
     "iopub.status.busy": "2024-03-26T17:30:07.285239Z",
     "iopub.status.idle": "2024-03-26T17:30:07.295514Z",
     "shell.execute_reply": "2024-03-26T17:30:07.294444Z",
     "shell.execute_reply.started": "2024-03-26T17:30:07.286045Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import EvalPrediction\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "def multi_label_metrics(predictions, labels):\n",
    "    probs = predictions  \n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_true = labels\n",
    "    y_pred[probs >= 0.5] = 1  \n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, probs, average='micro')  \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        'f1': f1_micro_average,\n",
    "        'roc_auc': roc_auc,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    result = multi_label_metrics(predictions=preds, labels=p.label_ids)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557ff6c",
   "metadata": {},
   "source": [
    "###  Creazione trainer, e allenamento per 5 epoche , l'ultima epoca non è stata completata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb22cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T00:22:29.895591Z",
     "iopub.status.busy": "2024-03-26T00:22:29.895233Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_34/199017382.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3810' max='4685' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3810/4685 11:57:09 < 2:44:47, 0.09 it/s, Epoch 4.06/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.524543</td>\n",
       "      <td>0.867200</td>\n",
       "      <td>0.912270</td>\n",
       "      <td>0.867200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.511300</td>\n",
       "      <td>0.487825</td>\n",
       "      <td>0.930067</td>\n",
       "      <td>0.959081</td>\n",
       "      <td>0.930067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.512700</td>\n",
       "      <td>0.473986</td>\n",
       "      <td>0.941800</td>\n",
       "      <td>0.967134</td>\n",
       "      <td>0.941800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/199017382.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
      "/tmp/ipykernel_34/199017382.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
      "/tmp/ipykernel_34/199017382.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
      "/tmp/ipykernel_34/199017382.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Definizione degli argomenti di training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    warmup_steps=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=4,\n",
    "    fp16=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    ") \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "    \n",
    ")\n",
    "\n",
    "# Addestramento\n",
    "trainer.train()\n",
    "\n",
    "# Salva il modello migliore\n",
    "model.save_pretrained(\"./best_model\")\n",
    "\n",
    "# Valutazione\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89caadc",
   "metadata": {},
   "source": [
    "### 5 epoca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f0be3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T17:33:02.118495Z",
     "iopub.status.busy": "2024-03-26T17:33:02.117832Z",
     "iopub.status.idle": "2024-03-26T19:36:24.397355Z",
     "shell.execute_reply": "2024-03-26T19:36:24.396372Z",
     "shell.execute_reply.started": "2024-03-26T17:33:02.118459Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_34/3630935219.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4500' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4500/4500 1:53:55, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.446900</td>\n",
       "      <td>0.477389</td>\n",
       "      <td>0.931667</td>\n",
       "      <td>0.965980</td>\n",
       "      <td>0.931667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/3630935219.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 09:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4799279272556305,\n",
       " 'eval_f1': 0.935,\n",
       " 'eval_roc_auc': 0.9624858119880568,\n",
       " 'eval_accuracy': 0.935,\n",
       " 'eval_runtime': 553.6594,\n",
       " 'eval_samples_per_second': 5.418,\n",
       " 'eval_steps_per_second': 0.677,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "model = ModifiedModelForBinaryClassification.from_pretrained(\"/kaggle/working/results/checkpoint-3750\").to(device)\n",
    "\n",
    "# Definizione degli argomenti di training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    warmup_steps=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=4,\n",
    "    fp16=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    resume_from_checkpoint = True,\n",
    "    \n",
    ") #save_strategy=\"epoch\"\n",
    "#load_best_model_at_end=True\n",
    " # Valuta ad ogni epoca\n",
    "    #logging_strategy=\"steps\",\n",
    "#logging_strategy=\"steps\",\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    \n",
    ")\n",
    "\n",
    "# Addestramento\n",
    "\n",
    "trainer.train(\"/kaggle/working/results/checkpoint-3750\")\n",
    "\n",
    "# Salva il modello migliore\n",
    "model.save_pretrained(\"./best_model\")\n",
    "\n",
    "# Valutazione\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78504a",
   "metadata": {},
   "source": [
    "### Allenato il modello , ho riadattato il codice per estrarre gli embeddings , prima il Dataloader e infinie il modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089b425f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:44:18.922741Z",
     "iopub.status.busy": "2024-03-28T08:44:18.921417Z",
     "iopub.status.idle": "2024-03-28T08:44:19.000634Z",
     "shell.execute_reply": "2024-03-28T08:44:18.999529Z",
     "shell.execute_reply.started": "2024-03-28T08:44:18.922707Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class SingleTextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=1024):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.texts):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=self.max_length, padding=\"max_length\", truncation=True)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed689754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:44:19.013094Z",
     "iopub.status.busy": "2024-03-28T08:44:19.012764Z",
     "iopub.status.idle": "2024-03-28T08:44:19.026871Z",
     "shell.execute_reply": "2024-03-28T08:44:19.025782Z",
     "shell.execute_reply.started": "2024-03-28T08:44:19.013056Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ModifiedModelForBinaryClassification(LongformerPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(ModifiedModelForBinaryClassification, self).__init__(config)\n",
    "        self.longformer = LongformerModel(config)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input_ids_1, attention_mask_1, input_ids_2=None, attention_mask_2=None, labels=None):\n",
    "    # global attention mask con attenzione solo sul primo token \n",
    "        global_attention_mask_1 = torch.zeros_like(input_ids_1)\n",
    "        global_attention_mask_1[:, 0] = 1 \n",
    "        \n",
    "        outputs_1 = self.longformer(input_ids_1, attention_mask=attention_mask_1, \n",
    "                                    global_attention_mask=global_attention_mask_1)\n",
    "        sequence_output_1 = outputs_1['last_hidden_state']\n",
    "        cls_token_1 = sequence_output_1[:, 0, :]  \n",
    "        \n",
    "        if input_ids_2 is None:\n",
    "            return cls_token_1\n",
    "        \n",
    "        \n",
    "        global_attention_mask_2 = torch.zeros_like(input_ids_2)\n",
    "        global_attention_mask_2[:, 0] = 1  \n",
    "        \n",
    "        outputs_2 = self.longformer(input_ids_2, attention_mask=attention_mask_2, \n",
    "                                    global_attention_mask=global_attention_mask_2)\n",
    "        sequence_output_2 = outputs_2['last_hidden_state']\n",
    "        cls_token_2 = sequence_output_2[:, 0, :]  \n",
    "        if(inference == True):\n",
    "            return cls_token_1,cls_token_2\n",
    "        logits = cosine_similarity(cls_token_1, cls_token_2).unsqueeze(-1)  # Assicurati che i logits siano della forma [batch_size, 1]\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "                loss_fct = nn.BCEWithLogitsLoss()\n",
    "                labels = labels.view(-1, 1).float()  # Ridimensiona le etichette per batch_size =1\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, logits) if loss is not None else logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0f392b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:44:19.029604Z",
     "iopub.status.busy": "2024-03-28T08:44:19.028674Z",
     "iopub.status.idle": "2024-03-28T08:44:21.510508Z",
     "shell.execute_reply": "2024-03-28T08:44:21.509542Z",
     "shell.execute_reply.started": "2024-03-28T08:44:19.029571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModifiedModelForBinaryClassification(\n",
       "  (longformer): LongformerModel(\n",
       "    (embeddings): LongformerEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): LongformerPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModifiedModelForBinaryClassification.from_pretrained(\"/kaggle/working/results/checkpoint-3750\").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0822f8",
   "metadata": {},
   "source": [
    "### Estrazione dei cls per i vari dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3253284b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T18:01:09.548141Z",
     "iopub.status.busy": "2024-03-27T18:01:09.547853Z",
     "iopub.status.idle": "2024-03-27T18:55:42.153688Z",
     "shell.execute_reply": "2024-03-27T18:55:42.152854Z",
     "shell.execute_reply.started": "2024-03-27T18:01:09.548117Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = SingleTextDataset(df[\"Text\"], tokenizer, max_length=1024)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids_1=input_ids, attention_mask_1=attention_mask)\n",
    "        \n",
    "        # Supponendo che il modello restituisca gli embeddings come parte dell'output\n",
    "        # Ad esempio, potresti avere modificato il modello per restituire il token CLS\n",
    "        embeddings.append(outputs.cpu().squeeze(1))\n",
    "        \n",
    "embeddings_def =  torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c450bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T18:55:42.155350Z",
     "iopub.status.busy": "2024-03-27T18:55:42.154918Z",
     "iopub.status.idle": "2024-03-27T18:56:34.210496Z",
     "shell.execute_reply": "2024-03-27T18:56:34.209613Z",
     "shell.execute_reply.started": "2024-03-27T18:55:42.155320Z"
    }
   },
   "outputs": [],
   "source": [
    "numpy_array = embeddings_def.numpy()\n",
    "df_t = pd.DataFrame(numpy_array)\n",
    "df_t.to_csv('emb_per_raffa_knn.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c50d9e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:44:21.511893Z",
     "iopub.status.busy": "2024-03-28T08:44:21.511630Z",
     "iopub.status.idle": "2024-03-28T08:44:22.263962Z",
     "shell.execute_reply": "2024-03-28T08:44:22.262909Z",
     "shell.execute_reply.started": "2024-03-28T08:44:21.511871Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/longformerdata/dataset_Longformer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d252d472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:44:47.663548Z",
     "iopub.status.busy": "2024-03-28T08:44:47.662844Z",
     "iopub.status.idle": "2024-03-28T08:44:47.712449Z",
     "shell.execute_reply": "2024-03-28T08:44:47.711594Z",
     "shell.execute_reply.started": "2024-03-28T08:44:47.663509Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['Text'].apply(lambda x: isinstance(x, str))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "031999b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:46:07.674000Z",
     "iopub.status.busy": "2024-03-28T08:46:07.673133Z",
     "iopub.status.idle": "2024-03-28T09:26:58.822302Z",
     "shell.execute_reply": "2024-03-28T09:26:58.821222Z",
     "shell.execute_reply.started": "2024-03-28T08:46:07.673962Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = SingleTextDataset(df_1[\"Text\"], tokenizer, max_length=1024)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "embeddingsl = []\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids_1=input_ids, attention_mask_1=attention_mask)\n",
    "        \n",
    "        embeddingsl.append(outputs.cpu().squeeze(1))\n",
    "        \n",
    "embeddings_def =  torch.cat(embeddingsl, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa56a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T09:29:34.794029Z",
     "iopub.status.busy": "2024-03-28T09:29:34.793114Z",
     "iopub.status.idle": "2024-03-28T09:30:15.129838Z",
     "shell.execute_reply": "2024-03-28T09:30:15.128783Z",
     "shell.execute_reply.started": "2024-03-28T09:29:34.793990Z"
    }
   },
   "outputs": [],
   "source": [
    "numpy_array = embeddings_def.numpy()\n",
    "df_l = pd.DataFrame(numpy_array)\n",
    "df_l.to_csv('emb_per_raffa_long.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "273f50be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T09:33:54.186674Z",
     "iopub.status.busy": "2024-03-28T09:33:54.185604Z",
     "iopub.status.idle": "2024-03-28T09:33:54.192100Z",
     "shell.execute_reply": "2024-03-28T09:33:54.191144Z",
     "shell.execute_reply.started": "2024-03-28T09:33:54.186637Z"
    }
   },
   "outputs": [],
   "source": [
    "df_2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bd16f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T09:34:16.805401Z",
     "iopub.status.busy": "2024-03-28T09:34:16.804997Z",
     "iopub.status.idle": "2024-03-28T10:15:37.097983Z",
     "shell.execute_reply": "2024-03-28T10:15:37.096390Z",
     "shell.execute_reply.started": "2024-03-28T09:34:16.805370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estrazione embeddings: 100%|██████████| 633/633 [41:20<00:00,  3.92s/batch]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dataset = SingleTextDataset(df_2[\"Text\"], tokenizer, max_length=1024)\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "model.eval()\n",
    "embeddingsl = []\n",
    "\n",
    "# Misura il numero totale di iterazioni\n",
    "total_iterations = len(data_loader)\n",
    "\n",
    "# Crea una barra di avanzamento\n",
    "progress_bar = tqdm(total=total_iterations, desc='Estrazione embeddings', unit='batch')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids_1=input_ids, attention_mask_1=attention_mask)\n",
    "        embeddingsl.append(outputs.cpu().squeeze(1))\n",
    "        \n",
    "        # Aggiorna la barra di avanzamento\n",
    "        progress_bar.update(1)\n",
    "\n",
    "# Ferma la barra di avanzamento\n",
    "progress_bar.close()\n",
    "\n",
    "embeddings_def = torch.cat(embeddingsl, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ced2acdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T10:15:37.099888Z",
     "iopub.status.busy": "2024-03-28T10:15:37.099602Z",
     "iopub.status.idle": "2024-03-28T10:16:17.855437Z",
     "shell.execute_reply": "2024-03-28T10:16:17.854336Z",
     "shell.execute_reply.started": "2024-03-28T10:15:37.099863Z"
    }
   },
   "outputs": [],
   "source": [
    "numpy_array = embeddings_def.numpy()\n",
    "df_l = pd.DataFrame(numpy_array)\n",
    "df_l.to_csv('emb_per_raffa_long_p2.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4669020,
     "sourceId": 7941315,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4674828,
     "sourceId": 7949493,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4678873,
     "sourceId": 7955174,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4682044,
     "sourceId": 7959388,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
